import os
import openai
from openai import AsyncOpenAI
import asyncio
import json
import httpx
import uuid
from fastapi import APIRouter, HTTPException, Response, Depends, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from app.utils.config import (
    OPENAI_API_KEY, OPENAI_BASE_URL,
    QDRANT_HOST, QDRANT_PORT, QDRANT_COLLECTION,
    IMAGE_BASE_URL, IMAGE_PATH_PREFIX, IS_OPENAI_CONFIGURED
)
from app.database import get_db
from app.models import Conversation, Message, User
from app.utils.auth import get_current_user
from app.utils.questionJudge import (
    judge_question_type,
    get_conversation_langgraph_context,
    log_question_processing
)
from sqlalchemy.orm import Session
from app.routes.llm_class import (
    StreamRequest,
)
from datetime import datetime

# Create router 
router = APIRouter()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë”© í™•ì¸
print(f"[Config] OpenAI API Key: {'ì„¤ì •ë¨' if OPENAI_API_KEY else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
print(f"[Config] Qdrant: {QDRANT_HOST}:{QDRANT_PORT} (ì»¬ë ‰ì…˜: {QDRANT_COLLECTION or 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'})")



# ì¼ë°˜ LLM ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ (streaming ì§€ì›)
@router.post("/chat/stream")
async def stream_chat_with_llm(request: StreamRequest, http_request: Request, db: Session = Depends(get_db)):
    """Stream a response from general LLM chat using async method"""
    try:
        # OpenAI API í‚¤ í™•ì¸
        if not OPENAI_API_KEY:
            return Response(content="Error: OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", media_type="text/plain")
        
        print(f"[Chat Stream] ========== LLM ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì‹œì‘ ==========")
        print(f"[Chat Stream] ìš”ì²­ ì •ë³´:")
        print(f"[Chat Stream] - ì§ˆë¬¸: {request.question}")
        print(f"[Chat Stream] - ëŒ€í™” ID: {request.conversation_id}")
        print(f"[Chat Stream] - conversation_id íƒ€ì…: {type(request.conversation_id)}")
        print(f"[Chat Stream] - conversation_idê°€ Noneì¸ê°€?: {request.conversation_id is None}")
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        system_content = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."
        
        # ë­ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ì¶”ê°€
        if request.include_langgraph_context and request.langgraph_context:
            langgraph_context = request.langgraph_context
            print(f"[Chat Stream] ë­ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ í¬í•¨: {langgraph_context}")
            
            # ë¬¸ì„œ ì •ë³´ë¥¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ì¶”ê°€
            if langgraph_context.get('documents'):
                documents_info = f"\n\nì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œ ì •ë³´:\n"
                for i, doc in enumerate(langgraph_context['documents'][:5], 1):  # ìµœëŒ€ 5ê°œ ë¬¸ì„œë§Œ
                    documents_info += f"{i}. {doc.get('title', 'ì œëª© ì—†ìŒ')}\n"
                    if doc.get('content'):
                        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
                        content = doc['content'][:500] + "..." if len(doc['content']) > 500 else doc['content']
                        documents_info += f"   ë‚´ìš©: {content}\n"
                    documents_info += "\n"
                
                system_content += documents_info
                system_content += "\nìœ„ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³  'ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”."
        
        messages = [{"role": "system", "content": system_content}]
        
        if request.conversation_id:
            try:
                # í•´ë‹¹ ëŒ€í™”ì˜ ì´ì „ ë©”ì‹œì§€ë“¤ ê°€ì ¸ì˜¤ê¸° (ìµœê·¼ 10ê°œë§Œ)
                conversation_messages = db.query(Message).filter(
                    Message.conversation_id == request.conversation_id
                ).order_by(Message.created_at.asc()).limit(10).all()
                
                print(f"[Chat Stream] ì´ì „ ëŒ€í™” ë©”ì‹œì§€ {len(conversation_messages)}ê°œ ë¡œë“œ")
                print(f"[Chat Stream] ========== ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ìƒì„¸ ì •ë³´ ==========")
                
                # ì´ì „ ëŒ€í™”ë¥¼ messagesì— ì¶”ê°€
                for i, msg in enumerate(conversation_messages):
                    print(f"[Chat Stream] DB ë©”ì‹œì§€ {i+1}: ID={msg.id}, role={msg.role}, created_at={msg.created_at}")
                    if msg.question:
                        print(f"[Chat Stream] ì§ˆë¬¸: {msg.question}")
                        messages.append({"role": "user", "content": msg.question})
                    if msg.ans:
                        print(f"[Chat Stream] ë‹µë³€: {msg.ans}")
                        messages.append({"role": "assistant", "content": msg.ans})
                    print(f"[Chat Stream] ----------------------------------------")
                
                print(f"[Chat Stream] ========== ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ ì™„ë£Œ ==========")
                        
            except Exception as e:
                print(f"[Chat Stream] ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
                # íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
        messages.append({"role": "user", "content": request.question})
        
        print(f"[Chat Stream] ì „ì†¡í•  ë©”ì‹œì§€ ê°œìˆ˜: {len(messages)}")
        print(f"[Chat Stream] ========== OpenAI APIì— ì „ì†¡í•  ì „ì²´ ë©”ì‹œì§€ ë‚´ìš© ==========")
        print(f"[Chat Stream] ==========ì „ì²´ ë©”ì‹œì§€ ë‚´ìš© : ")
        print(f"{messages}")
        
        print(f"[Chat Stream] ========== ì „ì²´ ë©”ì‹œì§€ ë‚´ìš© ë ==========")
        
        # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì‚¬ìš© - DB ì €ì¥ í¬í•¨
        return StreamingResponse(
            get_streaming_response_with_db_save(messages, http_request, request, db),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
                "Access-Control-Allow-Headers": "Content-Type, Authorization",
            }
        )
        
    except Exception as e:
        print(f"[Chat Stream] LLM ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì˜¤ë¥˜: {str(e)}")
        import traceback
        print(f"[Chat Stream] ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return Response(content=f"Error: {str(e)}", media_type="text/plain")


def get_conversation_context(conversation_id: int, db: Session) -> dict:
    """ëŒ€í™”ì˜ ì»¨í…ìŠ¤íŠ¸ì™€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸° (Judge í•¨ìˆ˜ ì‚¬ìš©)"""
    try:
        # Judge í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ LangGraph ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        langgraph_context = get_conversation_langgraph_context(conversation_id, db)
        
        # í•´ë‹¹ ëŒ€í™”ì˜ ëª¨ë“  ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (ì‹œê°„ìˆœ ì •ë ¬)
        messages = db.query(Message).filter(
            Message.conversation_id == conversation_id
        ).order_by(Message.created_at.asc()).all()
        
        print(f"[CONTEXT] ëŒ€í™” ID {conversation_id}ì˜ ë©”ì‹œì§€ {len(messages)}ê°œ ë¡œë“œ")
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ ì°¾ê¸° (LangGraph ì»¨í…ìŠ¤íŠ¸ì—ì„œ)
        first_message = None
        if langgraph_context["first_question"]:
            # ì²« ë²ˆì§¸ ì§ˆë¬¸ ë©”ì‹œì§€ ì°¾ê¸°
            for msg in messages:
                if msg.question == langgraph_context["first_question"]:
                    first_message = msg
                    print(f"[CONTEXT] ì²« ë²ˆì§¸ ì§ˆë¬¸ ë°œê²¬: ë©”ì‹œì§€ ID {msg.id}")
                    break
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        conversation_history = []
        for msg in messages:
            if msg.question:
                conversation_history.append({"role": "user", "content": msg.question})
            if msg.ans:
                conversation_history.append({"role": "assistant", "content": msg.ans})
        
        return {
            "first_message": first_message,
            "conversation_history": conversation_history,
            "message_count": len(messages),
            "langgraph_context": langgraph_context
        }
        
    except Exception as e:
        print(f"[CONTEXT] ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return {
            "first_message": None,
            "conversation_history": [],
            "message_count": 0,
            "langgraph_context": {}
        }

# ì¶”ê°€ ì§ˆë¬¸ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸
@router.post("/langgraph/followup/stream")
async def execute_followup_question_stream(request: StreamRequest, http_request: Request, db: Session = Depends(get_db), current_user: User = Depends(get_current_user)):
    """ì¶”ê°€ ì§ˆë¬¸ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ - ê¸°ì¡´ RAG ì»¨í…ìŠ¤íŠ¸ì™€ ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš©"""
    try:
        # OpenAI API í‚¤ í™•ì¸
        if not OPENAI_API_KEY:
            return Response(content="Error: OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", media_type="text/plain")
        
        print(f"[FOLLOWUP_STREAM] ğŸ”„ LLM ì¶”ê°€ ì§ˆë¬¸ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹œì‘: {request.question}")
        
        # ëŒ€í™” ID í™•ì¸
        if not request.conversation_id:
            return Response(content="Error: ì¶”ê°€ ì§ˆë¬¸ì€ conversation_idê°€ í•„ìš”í•©ë‹ˆë‹¤", media_type="text/plain")
        
        # Judge í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ìœ í˜• í™•ì¸
        judgment = judge_question_type(request.conversation_id, db)
        log_question_processing(request.question, judgment, current_user.id if current_user else None)
        
        if judgment["is_first_question"]:
            print(f"[FOLLOWUP_STREAM] âš ï¸ ìµœì´ˆ ì§ˆë¬¸ì´ ì¶”ê°€ ì§ˆë¬¸ ì—”ë“œí¬ì¸íŠ¸ë¡œ ì „ë‹¬ë¨")
            return Response(content="Error: ìµœì´ˆ ì§ˆë¬¸ì€ /langgraph/stream ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”", media_type="text/plain")
        
        # ê¸°ì¡´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì—ì„œ RAG ì •ë³´ ì¶”ì¶œ (Judge í•¨ìˆ˜ ì‚¬ìš©)
        context = get_conversation_context(request.conversation_id, db)
        
        if not context["first_message"]:
            print(f"[FOLLOWUP_STREAM] âš ï¸ ì²« ë²ˆì§¸ ì§ˆë¬¸ ì—†ìŒ")
            return Response(content="Error: ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", media_type="text/plain")
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ì˜ RAG ê²€ìƒ‰ ê²°ê³¼ í™œìš©
        first_message = context["first_message"]
        
        # DBì—ì„œ ì²« ë²ˆì§¸ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ RAG ê²€ìƒ‰ ê²°ê³¼ ì¬êµ¬ì„±
        # print(f"[FOLLOWUP_STREAM] ğŸ“„ ì²« ë²ˆì§¸ ì§ˆë¬¸ RAG ì •ë³´:")
        # print(f"[FOLLOWUP_STREAM]   ì§ˆë¬¸: {first_message.question}")
        # print(f"[FOLLOWUP_STREAM]   í‚¤ì›Œë“œ: {first_message.keyword}")
        # print(f"[FOLLOWUP_STREAM]   ê²€ìƒ‰ ë¬¸ì„œ: {first_message.db_contents}")
        
        # ì‹¤ì œ RAG ë¬¸ì„œ ë‚´ìš© êµ¬ì„± (DBì— ì €ì¥ëœ db_contents ì¬ì‚¬ìš©)
        document_title = "ê²€ìƒ‰ëœ ë¬¸ì„œ"
        actual_document_content = ""
        
        # DBì— ì €ì¥ëœ db_contentsì—ì„œ ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        try:
            if first_message.db_contents:
                # JSON íŒŒì‹±
                db_contents_list = json.loads(first_message.db_contents) if isinstance(first_message.db_contents, str) else first_message.db_contents
                
                if db_contents_list and len(db_contents_list) > 0:
                    # ì²« ë²ˆì§¸ ë¬¸ì„œ ì‚¬ìš©
                    top_doc = db_contents_list[0]
                    document_title = top_doc.get('document_name', 'ê²€ìƒ‰ëœ ë¬¸ì„œ')
                    
                    # ëª¨ë“  í…ìŠ¤íŠ¸ í•„ë“œ ê²°í•©
                    text_parts = []
                    for field in ['text', 'summary_purpose', 'summary_result', 'summary_fb']:
                        if top_doc.get(field):
                            text_parts.append(top_doc[field])
                    
                    actual_document_content = " ".join(text_parts).strip() or "ë¬¸ì„œ ë‚´ìš© ì—†ìŒ"
                    print(f"[FOLLOWUP_STREAM] DBì—ì„œ ë¬¸ì„œ ë‚´ìš© ë³µì› ì„±ê³µ: {document_title}")
                else:
                    actual_document_content = "ì €ì¥ëœ ë¬¸ì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
            else:
                actual_document_content = "ì €ì¥ëœ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"
                
        except Exception as e:
            print(f"[FOLLOWUP_STREAM] DB ë‚´ìš© íŒŒì‹± ì˜¤ë¥˜: {e}")
            import traceback
            print(f"[FOLLOWUP_STREAM] ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            actual_document_content = "ë¬¸ì„œ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        
        document_content = f"""
[ì›ë³¸ ì§ˆë¬¸] {first_message.question}
[ê²€ìƒ‰ëœ ë¬¸ì„œ] {document_title}
[ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©] {actual_document_content}
[ì´ì „ ë‹µë³€] {first_message.ans}
"""
        
        print(f"[FOLLOWUP_STREAM] ğŸ“„ ì¬ì‚¬ìš©í•  RAG ë¬¸ì„œ:")
        print(f"[FOLLOWUP_STREAM] ì œëª©: {document_title}")
        print(f"[FOLLOWUP_STREAM] ë‚´ìš©: {actual_document_content}")
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„± (ì²« ë²ˆì§¸ ì§ˆë¬¸ê³¼ ë‹µë³€ë§Œ í¬í•¨)
        conversation_history = context["conversation_history"]
        print(f"[FOLLOWUP_STREAM] ğŸ’¬ ëŒ€í™” íˆìŠ¤í† ë¦¬: {len(conversation_history)}ê°œ ë©”ì‹œì§€")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (RAG ë¬¸ì„œ ê¸°ë°˜)
        system_prompt = f"""ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ê°€ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

{document_content}

ì¤‘ìš”í•œ ê·œì¹™:
1. ìœ„ì— ì œê³µëœ ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ì¶”ê°€ì ì¸ ì •ë³´ë‚˜ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”
4. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”
5. ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”"""
        
        # LLM API í˜¸ì¶œì„ ìœ„í•œ ë©”ì‹œì§€ êµ¬ì„±
        messages = [{"role": "system", "content": system_prompt}]
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ)
        recent_history = conversation_history[-10:] if len(conversation_history) > 10 else conversation_history
        messages.extend(recent_history)
        
        # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
        messages.append({"role": "user", "content": request.question})
        
        print(f"[FOLLOWUP_STREAM] ğŸ“¤ LLMì— ì „ì†¡í•  ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
        print(f"[FOLLOWUP_STREAM] ğŸ“ í˜„ì¬ ì§ˆë¬¸: {request.question}")
        print(f"[FOLLOWUP_STREAM] ğŸ‘¤ ì‚¬ìš©ì: {current_user.username if current_user else 'None'}")
        
        # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì‚¬ìš© - DB ì €ì¥ í¬í•¨
        return StreamingResponse(
            get_streaming_response_with_db_save(messages, http_request, request, db, current_user),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
                "Access-Control-Allow-Headers": "Content-Type, Authorization",
            }
        )
        
    except Exception as e:
        print(f"[FOLLOWUP_STREAM] LLM ì¶”ê°€ ì§ˆë¬¸ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        import traceback
        print(f"[FOLLOWUP_STREAM] ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return Response(content=f"Error: {str(e)}", media_type="text/plain")

async def save_message_to_db(stream_request: StreamRequest, assistant_response: str, image_url: str = None, db: Session = None, current_user: User = None):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥
    
    ì¤‘ìš”: ì´ ì‹œìŠ¤í…œì—ì„œëŠ” ì§ˆë¬¸ê³¼ ë‹µë³€ì´ í•˜ë‚˜ì˜ Message rowì— ì €ì¥ë©ë‹ˆë‹¤.
    - question í•„ë“œ: ì‚¬ìš©ì ì§ˆë¬¸
    - ans í•„ë“œ: AI ë‹µë³€
    - role: 'user' (ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ëª¨ë‘ user ë©”ì‹œì§€ì— í¬í•¨)
    - ë³„ë„ì˜ assistant ë©”ì‹œì§€ëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ
    """
    try:
        if not db:
            print(f"[DB_SAVE] âŒ DB ì„¸ì…˜ì´ ì—†ìŒ")
            return
            
        if not stream_request.conversation_id:
            print(f"[DB_SAVE] âŒ conversation_idê°€ ì—†ìŒ - ì¶”ê°€ ì§ˆë¬¸ì€ conversation_idê°€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            return
            
        print(f"[DB_SAVE] ğŸ’¾ ë©”ì‹œì§€ DB ì €ì¥ ì‹œì‘")
        print(f"[DB_SAVE] - ëŒ€í™” ID: {stream_request.conversation_id}")
        print(f"[DB_SAVE] - ì§ˆë¬¸: {stream_request.question}")
        print(f"[DB_SAVE] - ë‹µë³€ ê¸¸ì´: {len(assistant_response)}ì")
        print(f"[DB_SAVE] - ì‚¬ìš©ì: {current_user.username if current_user else 'None'}")
        
        # ëŒ€í™” ì¡´ì¬ í™•ì¸
        conversation = db.query(Conversation).filter(
            Conversation.id == stream_request.conversation_id,
            Conversation.is_deleted == False
        ).first()
        
        if not conversation:
            print(f"[DB_SAVE] âŒ ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {stream_request.conversation_id}")
            return
        
        print(f"[DB_SAVE] âœ… ê¸°ì¡´ ëŒ€í™” ì°¾ìŒ - ìƒˆ conversation ìƒì„±í•˜ì§€ ì•ŠìŒ")
            
        # ì‚¬ìš©ì ì •ë³´ í™•ì¸ (current_user ìš°ì„ , ì—†ìœ¼ë©´ conversation.user)
        user_name = "system"  # ê¸°ë³¸ê°’
        if current_user:
            user_name = current_user.loginid or current_user.username or "system"
            print(f"[DB_SAVE] - current_userì—ì„œ ì‚¬ìš©ìëª… ê°€ì ¸ì˜´: {user_name}")
        elif conversation.user:
            user_name = conversation.user.loginid or conversation.user.username or "system"
            print(f"[DB_SAVE] - conversation.userì—ì„œ ì‚¬ìš©ìëª… ê°€ì ¸ì˜´: {user_name}")
        
        # ì¤‘ë³µ ì €ì¥ ë°©ì§€ - ë™ì¼í•œ ì§ˆë¬¸ì˜ ìµœê·¼ ë©”ì‹œì§€ í™•ì¸ (30ì´ˆ ì´ë‚´)
        from datetime import datetime, timedelta
        recent_time = datetime.utcnow() - timedelta(seconds=30)
        
        print(f"[DB_SAVE] ğŸ” ì¤‘ë³µ ì €ì¥ ë°©ì§€ í™•ì¸:")
        print(f"[DB_SAVE]   - conversation_id: {stream_request.conversation_id}")
        print(f"[DB_SAVE]   - question: {stream_request.question[:50]}...")
        print(f"[DB_SAVE]   - recent_time: {recent_time}")
        
        existing_message = db.query(Message).filter(
            Message.conversation_id == stream_request.conversation_id,
            Message.question == stream_request.question,
            Message.created_at >= recent_time
        ).first()
        
        if existing_message:
            print(f"[DB_SAVE] âš ï¸ ì¤‘ë³µ ë©”ì‹œì§€ ê°ì§€ë¨. ê¸°ì¡´ ë©”ì‹œì§€ ID: {existing_message.id}")
            print(f"[DB_SAVE]   - ê¸°ì¡´ ë©”ì‹œì§€ ìƒì„± ì‹œê°„: {existing_message.created_at}")
            print(f"[DB_SAVE]   - í˜„ì¬ ì‹œê°„: {datetime.utcnow()}")
            return
        
        # ë©”ì‹œì§€ ìƒì„± ë° ì €ì¥
        # ì¤‘ìš”: ì§ˆë¬¸ê³¼ ë‹µë³€ì´ í•˜ë‚˜ì˜ rowì— ì €ì¥ë˜ëŠ” êµ¬ì¡°
        # - question: ì‚¬ìš©ì ì§ˆë¬¸
        # - ans: AI ë‹µë³€ (ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œëœ ë‚´ìš©)
        # - role: 'user' (ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ëª¨ë‘ user ë©”ì‹œì§€ì— í¬í•¨)
        # q_modeëŠ” conversation_idê°€ ìˆëŠ” ê²½ìš° 'add', ì—†ëŠ” ê²½ìš° None
        # conversation_idê°€ ìˆìœ¼ë©´ ê¸°ì¡´ ëŒ€í™”ì— ì¶”ê°€ ì§ˆë¬¸ì´ë¯€ë¡œ 'add'
        # conversation_idê°€ ì—†ìœ¼ë©´ ìƒˆ ëŒ€í™”ì´ë¯€ë¡œ None (ì²« ë²ˆì§¸ ì§ˆë¬¸)
        q_mode_value = "add" if stream_request.conversation_id else None
        
        print(f"[DB_SAVE] - q_mode: {q_mode_value} (conversation_id: {stream_request.conversation_id})")
        
        message = Message(
            conversation_id=stream_request.conversation_id,
            role="user",
            question=stream_request.question,  # ì‚¬ìš©ì ì§ˆë¬¸
            ans=assistant_response,  # AI ë‹µë³€ (ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œëœ ë‚´ìš©)
            user_name=user_name,
            q_mode=q_mode_value,  # conversation_idê°€ ìˆìœ¼ë©´ 'add', ì—†ìœ¼ë©´ None
            image=image_url
        )
        
        db.add(message)
        
        # ëŒ€í™”ì˜ last_updated ì‹œê°„ ì—…ë°ì´íŠ¸
        conversation.last_updated = datetime.utcnow()
        
        # ëŒ€í™”ì— ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¸ ê²½ìš° íƒ€ì´í‹€ ì„¤ì • (ì¶”ê°€ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        if (not conversation.title or conversation.title == "New Conversation") and stream_request.q_mode != "add":
            title = stream_request.question[:50]
            if len(stream_request.question) > 50:
                title += "..."
            conversation.title = title
            print(f"[DB_SAVE] ğŸ“ ëŒ€í™” íƒ€ì´í‹€ ì„¤ì •: {title}")
        
        db.commit()
        db.refresh(message)
        db.refresh(conversation)
        
        print(f"[DB_SAVE] âœ… ë©”ì‹œì§€ ì €ì¥ ì™„ë£Œ. ID: {message.id}")
        
    except Exception as e:
        print(f"[DB_SAVE] âŒ DB ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        import traceback
        print(f"[DB_SAVE] ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        if db:
            db.rollback()


async def get_streaming_response_with_db_save(messages: List[Dict], request: Request, stream_request: StreamRequest, db: Session, current_user: User = None):
    """Stream a response from LLM using AsyncOpenAI with custom headers and save to DB"""
    try:
        print(f"[LLM_STREAM_DB] ğŸš€ LLM ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ (DB ì €ì¥ í¬í•¨)")
        
        # ì´ë¯¸ì§€ URL (ì´ë¯¸ì§€ ìƒì„±ì´ ìš”ì²­ëœ ê²½ìš°)
        image_url = None
        if stream_request.generate_image:
            # ì´ë¯¸ì§€ ìƒì„±ì€ ë³„ë„ ì‹œìŠ¤í…œì—ì„œ ì²˜ë¦¬
            print(f"[LLM_STREAM_DB] ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ë¨ (ë³„ë„ ì‹œìŠ¤í…œ í•„ìš”)")
            image_url = None  # ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œ ì—°ë™ í•„ìš”
        
        # API í‚¤ ê²€ì¦
        if not IS_OPENAI_CONFIGURED:
            error_payload = json.dumps({'error': 'AI ì„œë¹„ìŠ¤ ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.'}, ensure_ascii=False)
            yield (f"data: {error_payload}\n\n").encode("utf-8")
            yield "data: [DONE]\n\n".encode("utf-8")
            return

        # httpx í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (íƒ€ì„ì•„ì›ƒ ì¶”ê°€)
        httpx_client = httpx.AsyncClient(
            verify=False, 
            timeout=httpx.Timeout(30.0, connect=10.0)
        )

        # AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = AsyncOpenAI(
                api_key=OPENAI_API_KEY,
                base_url=OPENAI_BASE_URL,
                http_client=httpx_client,
                default_headers={
                    "x-dep-ticket": OPENAI_API_KEY,
                    "Send-System-Name": "ds2llm",
                    "User-Id": "c.seunghoon",
                    "User-Type": "AD_ID",
                    "Prompt-Msg-Id": str(uuid.uuid4()),
                    "Completion-Msg-Id": str(uuid.uuid4()),
                }
            )
            
        # ë¹„ë™ê¸° í˜¸ì¶œ
        response = await client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                stream=True,
            )
        
        print(f"[LLM_STREAM_DB] ğŸ“¥ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘")
        
        text_response = ""
        async for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                text_response += content
                
                try:
                    # ë¹„-ASCII ë¬¸ì í—ˆìš©, UTF-8 bytesë¡œ ì¦‰ì‹œ ì „ì†¡
                    payload = json.dumps({'content': content}, ensure_ascii=False)
                    yield (f"data: {payload}\n\n").encode("utf-8")
                    # ì§€ì—° ì œê±° - ë¹ ë¥¸ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•´
                except (ConnectionResetError, BrokenPipeError, OSError, ConnectionAbortedError, ConnectionError) as e:
                    # í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ì´ ëŠì–´ì§„ ê²½ìš° ì¡°ìš©íˆ ì¢…ë£Œ
                    print(f"[LLM_STREAM_DB] Client disconnected during streaming lv2: {type(e).__name__}")
                    return
                except Exception as e:
                    print(f"[LLM_STREAM_DB] Unexpected error during streaming lv1: {str(e)}")
                    return
        
        # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ DBì— ì €ì¥ (ì¶”ê°€ì§ˆë¬¸ì˜ ê²½ìš° ì´ë¯¸ prepareì—ì„œ ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ)
        print(f"[LLM_STREAM_DB] ğŸ” ì €ì¥ ì¡°ê±´ í™•ì¸:")
        print(f"[LLM_STREAM_DB]   - conversation_id: {stream_request.conversation_id}")
        print(f"[LLM_STREAM_DB]   - q_mode: {getattr(stream_request, 'q_mode', 'None')}")
        print(f"[LLM_STREAM_DB]   - is_add_question: {getattr(stream_request, 'q_mode', None) == 'add'}")
        
        if not stream_request.conversation_id or getattr(stream_request, 'q_mode', None) != "add":
            try:
                print(f"[LLM_STREAM_DB] ğŸ’¾ DB ì €ì¥ ì‹œì‘ (ì¼ë°˜ ì§ˆë¬¸)")
                await save_message_to_db(stream_request, text_response, image_url, db, current_user)
                print(f"[LLM_STREAM_DB] âœ… DB ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                print(f"[LLM_STREAM_DB] âŒ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ìŠ¤íŠ¸ë¦¬ë°ì€ ê³„ì† ì§„í–‰
        else:
            # ì¶”ê°€ì§ˆë¬¸ì¸ ê²½ìš° message_idê°€ ìˆìœ¼ë©´ ê¸°ì¡´ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
            if hasattr(stream_request, 'message_id') and stream_request.message_id:
                try:
                    print(f"[LLM_STREAM_DB] ğŸ’¾ ê¸°ì¡´ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸: message_id={stream_request.message_id}")
                    existing_message = db.query(Message).filter(
                        Message.id == stream_request.message_id,
                        Message.conversation_id == stream_request.conversation_id
                    ).first()
                    
                    if existing_message:
                        existing_message.ans = text_response
                        if image_url:
                            # ì´ë¯¸ì§€ URLì´ ìˆëŠ” ê²½ìš° ì¶”ê°€ ì²˜ë¦¬ (í•„ìš”ì‹œ)
                            print(f"[LLM_STREAM_DB] ğŸ–¼ï¸ ì´ë¯¸ì§€ URL ì €ì¥: {image_url}")
                        db.commit()
                        print(f"[LLM_STREAM_DB] âœ… ë©”ì‹œì§€ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {stream_request.message_id}")
                    else:
                        print(f"[LLM_STREAM_DB] âš ï¸ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {stream_request.message_id}")
                except Exception as e:
                    print(f"[LLM_STREAM_DB] âŒ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
                    db.rollback()
            else:
                print(f"[LLM_STREAM_DB] â­ï¸ ì¶”ê°€ì§ˆë¬¸ - message_id ì—†ìŒ, DB ì €ì¥ ìŠ¤í‚µ")
                print(f"[LLM_STREAM_DB]   - prepare ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì´ë¯¸ ë©”ì‹œì§€ê°€ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ì €ì¥ ë°©ì§€")
        
        # í…ìŠ¤íŠ¸ ì‘ë‹µì´ ì™„ë£Œëœ í›„ ì´ë¯¸ì§€ URLì´ ìˆìœ¼ë©´ ì „ì†¡
        if image_url:
            try:
                response_data = {
                    "text": text_response,
                    "image_url": image_url
                }
                payload = json.dumps(response_data, ensure_ascii=False)
                yield (f"data: {payload}\n\n").encode("utf-8")
            except Exception as e:
                print(f"[LLM_STREAM_DB] Error sending image data: {str(e)}")
        
        print(f"[LLM_STREAM_DB] âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")
        yield "data: [DONE]\n\n".encode("utf-8")
        
    except Exception as e:
        error_message = str(e)
        print(f"[LLM_STREAM_DB] Error in streaming response: {error_message}")
        import traceback
        print(f"[LLM_STREAM_DB] ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        
        try:
            # ì—°ê²° ì˜¤ë¥˜ íƒ€ì…ë³„ ì²˜ë¦¬
            if "APIConnectionError" in error_message or "Connection error" in error_message:
                error_desc = "AI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif "timeout" in error_message.lower():
                error_desc = "AI ì„œë¹„ìŠ¤ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif "authentication" in error_message.lower() or "unauthorized" in error_message.lower():
                error_desc = "AI ì„œë¹„ìŠ¤ ì¸ì¦ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            else:
                error_desc = "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            error_payload = json.dumps({'error': error_desc}, ensure_ascii=False)
            yield (f"data: {error_payload}\n\n").encode("utf-8")
            yield "data: [DONE]\n\n".encode("utf-8")
        except Exception:
            # ì—ëŸ¬ ì „ì†¡ë„ ì‹¤íŒ¨í•œ ê²½ìš° ì¡°ìš©íˆ ì¢…ë£Œ
            return

async def get_streaming_response_async(messages: List[Dict], request: Request, generate_image: bool = False):
    """Stream a response from LLM using AsyncOpenAI with custom headers"""
    try:
        print(f"[LLM_STREAM] ğŸš€ LLM ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
        
        # ì´ë¯¸ì§€ URL (ì´ë¯¸ì§€ ìƒì„±ì´ ìš”ì²­ëœ ê²½ìš°)
        image_url = None
        if generate_image:
            # ì´ë¯¸ì§€ ìƒì„±ì€ ë³„ë„ ì‹œìŠ¤í…œì—ì„œ ì²˜ë¦¬
            print(f"[LLM_STREAM] ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ë¨ (ë³„ë„ ì‹œìŠ¤í…œ í•„ìš”)")
            image_url = None  # ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œ ì—°ë™ í•„ìš”
        
        # API í‚¤ ê²€ì¦
        if not IS_OPENAI_CONFIGURED:
            error_payload = json.dumps({'error': 'AI ì„œë¹„ìŠ¤ ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.'}, ensure_ascii=False)
            yield (f"data: {error_payload}\n\n").encode("utf-8")
            yield "data: [DONE]\n\n".encode("utf-8")
            return

        # httpx í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (íƒ€ì„ì•„ì›ƒ ì¶”ê°€)
        httpx_client = httpx.AsyncClient(
            verify=False, 
            timeout=httpx.Timeout(30.0, connect=10.0)
        )

        # print(f"[messages í™•ì¸] {messages}")              
        

        # AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = AsyncOpenAI(
                api_key=OPENAI_API_KEY,
                base_url=OPENAI_BASE_URL,
                http_client=httpx_client,
                default_headers={
                    "x-dep-ticket": OPENAI_API_KEY,
                    "Send-System-Name": "ds2llm",
                    "User-Id": "c.seunghoon",
                    "User-Type": "AD_ID",
                    "Prompt-Msg-Id": str(uuid.uuid4()),
                    "Completion-Msg-Id": str(uuid.uuid4()),
                }
            )
            
        # ë¹„ë™ê¸° í˜¸ì¶œ
        response = await client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                stream=True,
            )
        
        print(f"[LLM_STREAM] ğŸ“¥ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘")
        
        text_response = ""
        async for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                text_response += content
                
                try:
                    # ë¹„-ASCII ë¬¸ì í—ˆìš©, UTF-8 bytesë¡œ ì¦‰ì‹œ ì „ì†¡
                    payload = json.dumps({'content': content}, ensure_ascii=False)
                    yield (f"data: {payload}\n\n").encode("utf-8")
                    # ì§€ì—° ì œê±° - ë¹ ë¥¸ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•´
                except (ConnectionResetError, BrokenPipeError, OSError, ConnectionAbortedError, ConnectionError) as e:
                    # í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ì´ ëŠì–´ì§„ ê²½ìš° ì¡°ìš©íˆ ì¢…ë£Œ
                    print(f"[LLM_STREAM] Client disconnected during streaming lv2: {type(e).__name__}")
                    return
                except Exception as e:
                    print(f"[LLM_STREAM] Unexpected error during streaming lv1: {str(e)}")
                    return
        
        # í…ìŠ¤íŠ¸ ì‘ë‹µì´ ì™„ë£Œëœ í›„ ì´ë¯¸ì§€ URLì´ ìˆìœ¼ë©´ ì „ì†¡
        if image_url:
            try:
                response_data = {
                    "text": text_response,
                    "image_url": image_url
                }
                payload = json.dumps(response_data, ensure_ascii=False)
                yield (f"data: {payload}\n\n").encode("utf-8")
            except Exception as e:
                print(f"[LLM_STREAM] Error sending image data: {str(e)}")
        
        print(f"[LLM_STREAM] âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")
        yield "data: [DONE]\n\n".encode("utf-8")
        
    except Exception as e:
        error_message = str(e)
        print(f"[LLM_STREAM] Error in streaming response: {error_message}")
        import traceback
        print(f"[LLM_STREAM] ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        
        try:
            # ì—°ê²° ì˜¤ë¥˜ íƒ€ì…ë³„ ì²˜ë¦¬
            if "APIConnectionError" in error_message or "Connection error" in error_message:
                error_desc = "AI ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif "timeout" in error_message.lower():
                error_desc = "AI ì„œë¹„ìŠ¤ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif "authentication" in error_message.lower() or "unauthorized" in error_message.lower():
                error_desc = "AI ì„œë¹„ìŠ¤ ì¸ì¦ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            else:
                error_desc = "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            error_payload = json.dumps({'error': error_desc}, ensure_ascii=False)
            yield (f"data: {error_payload}\n\n").encode("utf-8")
            yield "data: [DONE]\n\n".encode("utf-8")
        except Exception:
            # ì—ëŸ¬ ì „ì†¡ë„ ì‹¤íŒ¨í•œ ê²½ìš° ì¡°ìš©íˆ ì¢…ë£Œ
            return
