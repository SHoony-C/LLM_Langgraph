from typing import List
from pydantic import BaseModel
from typing import Optional
import asyncio

# ì§ì ‘ êµ¬í˜„í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° í´ë˜ìŠ¤
class DirectSimilarityCalculator:
    def __init__(self):
        self.stopwords = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ì™€', 'ê³¼', 'ì˜', 'ë¡œ', 'ìœ¼ë¡œ', 'í•œ', 'í•˜ëŠ”', 'í•˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ê·¸', 'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì €ê²ƒ'}
        
    def preprocess_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° í† í°í™”"""
        import re
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
        cleaned_text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', text.lower())
        # í† í°í™”
        tokens = cleaned_text.split()
        # ë¶ˆìš©ì–´ ì œê±° ë° ê¸¸ì´ 2 ì´ìƒ í† í°ë§Œ ìœ ì§€
        filtered_tokens = [token for token in tokens if token not in self.stopwords and len(token) >= 2]
        return filtered_tokens
    
    def calculate_jaccard_similarity(self, text1: str, text2: str) -> float:
        """ìì¹´ë“œ ìœ ì‚¬ë„ ê³„ì‚°"""
        tokens1 = set(self.preprocess_text(text1))
        tokens2 = set(self.preprocess_text(text2))
        
        if not tokens1 and not tokens2:
            return 1.0
        if not tokens1 or not tokens2:
            return 0.0
            
        intersection = len(tokens1.intersection(tokens2))
        union = len(tokens1.union(tokens2))
        
        return intersection / union if union > 0 else 0.0
    
    def calculate_cosine_similarity(self, text1: str, text2: str) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (TF ê¸°ë°˜)"""
        tokens1 = self.preprocess_text(text1)
        tokens2 = self.preprocess_text(text2)
        
        # TF ê³„ì‚°
        tf1 = {}
        tf2 = {}
        
        for token in tokens1:
            tf1[token] = tf1.get(token, 0) + 1
        for token in tokens2:
            tf2[token] = tf2.get(token, 0) + 1
        
        # ì „ì²´ ë‹¨ì–´ ì§‘í•©
        all_tokens = set(tokens1 + tokens2)
        
        if not all_tokens:
            return 1.0
        
        # ë²¡í„° ìƒì„±
        vector1 = [tf1.get(token, 0) for token in all_tokens]
        vector2 = [tf2.get(token, 0) for token in all_tokens]
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        dot_product = sum(a * b for a, b in zip(vector1, vector2))
        magnitude1 = sum(a * a for a in vector1) ** 0.5
        magnitude2 = sum(b * b for b in vector2) ** 0.5
        
        if magnitude1 == 0 or magnitude2 == 0:
            return 0.0
            
        return dot_product / (magnitude1 * magnitude2)
    
    def calculate_combined_similarity(self, text1: str, text2: str) -> float:
        """ìì¹´ë“œì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ ìµœì¢… ìœ ì‚¬ë„"""
        jaccard_sim = self.calculate_jaccard_similarity(text1, text2)
        cosine_sim = self.calculate_cosine_similarity(text1, text2)
        
        # ê°€ì¤‘ í‰ê·  (ìì¹´ë“œ 0.4, ì½”ì‚¬ì¸ 0.6)
        combined_sim = (jaccard_sim * 0.4) + (cosine_sim * 0.6)
        return combined_sim
    
    def find_similar_documents(self, query: str, documents: List[dict], top_k: int = 5) -> List[dict]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì„ ì°¾ì•„ ë°˜í™˜"""
        results = []
        
        for doc in documents:
            # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ - ëª¨ë“  ê´€ë ¨ í•„ë“œ ê²°í•©
            doc_title = doc.get('document_name', '')
            
            # ëª¨ë“  í…ìŠ¤íŠ¸ í•„ë“œë¥¼ ê²°í•©í•˜ì—¬ í’ë¶€í•œ ë‚´ìš© ìƒì„±
            text_parts = [doc_title]  # ì œëª©ì€ í•­ìƒ í¬í•¨
            
            if 'vector' in doc and isinstance(doc['vector'], dict):
                vector_data = doc['vector']
                # ëª¨ë“  í…ìŠ¤íŠ¸ í•„ë“œë¥¼ ê²°í•© (ì‹¤ì œ DB êµ¬ì¡°ì— ë§ì¶¤)
                for field in ['text', 'summary_purpose', 'summary_result', 'summary_fb']:
                    if field in vector_data and vector_data[field]:
                        text_parts.append(str(vector_data[field]))
            
            # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê³µë°±ìœ¼ë¡œ ì—°ê²°
            doc_text = " ".join(text_parts).strip()
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarity = self.calculate_combined_similarity(query, doc_text)
            
            results.append({
                'document': doc,
                'similarity': similarity,
                'matched_text': doc_text[:200] + '...' if len(doc_text) > 200 else doc_text
            })
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ kê°œ ë°˜í™˜
        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results[:top_k]

# ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ì„ ìœ„í•œ í´ë˜ìŠ¤
class StreamRequest(BaseModel):
    question: str
    conversation_id: Optional[int] = None
    message_id: Optional[int] = None  # ì˜êµ¬ ë©”ì‹œì§€ ID ì¶”ê°€
    generate_image: Optional[bool] = False  # ì´ë¯¸ì§€ ìƒì„± í”Œë˜ê·¸ ì¶”ê°€
    # LangGraph ì»¨í…ìŠ¤íŠ¸ í•„ë“œ ì¶”ê°€
    langgraph_context: Optional[dict] = None
    include_langgraph_context: Optional[bool] = False
    q_mode: Optional[str] = None  # ì§ˆë¬¸ ëª¨ë“œ ì¶”ê°€ (add, search ë“±)

# LangGraph ìƒíƒœ ì •ì˜
class SearchState(dict):
    question: str       # ì‚¬ìš©ì ì…ë ¥ ì§ˆì˜
    keyword: str       # ì‚¬ìš©ì ì…ë ¥ ì§ˆì˜
    candidates_each: List[dict] 
    candidates_total: List[dict] 
    response: List[dict]     # LLMì´ ìƒì„±í•œ ì‘ë‹µ
    generator_id: str   # SSE ì œë„ˆë ˆì´í„° ID

# SSE ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì œë„ˆë ˆì´í„° í´ë˜ìŠ¤
class SSEGenerator:
    def __init__(self, generator_id: str):
        self.generator_id = generator_id
        self.message_queue = asyncio.Queue()
        self.is_active = True
        self.message_count = 0
        print(f"[SSE_GEN] ğŸ†• SSEGenerator ìƒì„±: {generator_id}")
        
    async def send_message(self, message: dict):
        """ë©”ì‹œì§€ë¥¼ íì— ì¶”ê°€"""
        if self.is_active:
            self.message_count += 1
            # print(f"[SSE_GEN] ğŸ“¥ ë©”ì‹œì§€ #{self.message_count} íì— ì¶”ê°€: {message.get('stage', 'unknown')}:{message.get('status', 'unknown')}")
            await self.message_queue.put(message)
            # print(f"[SSE_GEN] âœ… ë©”ì‹œì§€ í ì¶”ê°€ ì™„ë£Œ, í˜„ì¬ í í¬ê¸°: {self.message_queue.qsize()}")
        else:
            print(f"[SSE_GEN] âŒ ë¹„í™œì„± ì œë„ˆë ˆì´í„°ì— ë©”ì‹œì§€ ì „ì†¡ ì‹œë„: {self.generator_id}")
    
    async def close(self):
        """ì œë„ˆë ˆì´í„° ì¢…ë£Œ"""
        print(f"[SSE_GEN] ğŸ”š ì œë„ˆë ˆì´í„° ì¢…ë£Œ ì‹œì‘: {self.generator_id}")
        self.is_active = False
        await self.message_queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸
        print(f"[SSE_GEN] âœ… ì œë„ˆë ˆì´í„° ì¢…ë£Œ ì™„ë£Œ: {self.generator_id}")
